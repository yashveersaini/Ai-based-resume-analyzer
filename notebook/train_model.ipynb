{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì ResumeIQ ‚Äî Job Role Prediction Model Training\n",
    "\n",
    "This notebook trains a **TF-IDF + Logistic Regression** classifier to predict the top job roles from resume skills.\n",
    "\n",
    "### üìÇ Input file:\n",
    "- `training_data.json` ‚Äî dataset of skill strings + job role labels. Add more entries here to improve accuracy.\n",
    "\n",
    "### üì¶ Output files (saved into `models/` folder):\n",
    "- `models/job_model.pkl` ‚Äî trained Logistic Regression classifier\n",
    "- `models/tfidf.pkl` ‚Äî fitted TF-IDF vectorizer\n",
    "- `models/label_encoder.pkl` ‚Äî label encoder for job role names\n",
    "\n",
    "### ‚ñ∂ How to run:\n",
    "```bash\n",
    "pip install scikit-learn pandas numpy joblib\n",
    "jupyter notebook train_model.ipynb\n",
    "```\n",
    "Run all cells top to bottom. The model files will be saved automatically.\n",
    "\n",
    "### ‚úèÔ∏è To add more training data:\n",
    "Open `training_data.json` and add entries in this format:\n",
    "```json\n",
    "{ \"skills\": \"python docker kubernetes aws git\", \"job_role\": \"DevOps Engineer\" }\n",
    "```\n",
    "Then re-run the notebook to retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML PROJECTS\\\\AI-Based-Resume-analyser\\\\notebook'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML PROJECTS\\\\AI-Based-Resume-analyser'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 samples from data\\training_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load from JSON file \n",
    "JSON_PATH = os.path.join('data', 'training_data.json')\n",
    "\n",
    "with open(JSON_PATH, 'r') as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw)   \n",
    "\n",
    "# Validate expected columns exist\n",
    "assert 'skills'   in df.columns, \"JSON must have a 'skills' field\"\n",
    "assert 'job_role' in df.columns, \"JSON must have a 'job_role' field\"\n",
    "\n",
    "print(f'Loaded {len(df)} samples from {JSON_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 unique job roles\n",
      "\n",
      "job_role\n",
      "Data Scientist            10\n",
      "Web Developer             10\n",
      "DevOps Engineer           10\n",
      "Data Analyst              10\n",
      "Backend Developer         10\n",
      "Mobile Developer          10\n",
      "Cybersecurity Analyst     10\n",
      "Cloud Engineer            10\n",
      "ML Engineer               10\n",
      "Database Administrator    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'   {df[\"job_role\"].nunique()} unique job roles\\n')\n",
    "print(df['job_role'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Role ‚Üí Label mapping:\n",
      "   0 ‚Üí Backend Developer\n",
      "   1 ‚Üí Cloud Engineer\n",
      "   2 ‚Üí Cybersecurity Analyst\n",
      "   3 ‚Üí Data Analyst\n",
      "   4 ‚Üí Data Scientist\n",
      "   5 ‚Üí Database Administrator\n",
      "   6 ‚Üí DevOps Engineer\n",
      "   7 ‚Üí ML Engineer\n",
      "   8 ‚Üí Mobile Developer\n",
      "   9 ‚Üí Web Developer\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['job_role'])\n",
    "\n",
    "print('Job Role ‚Üí Label mapping:')\n",
    "for role, label in zip(le.classes_, range(len(le.classes_))):\n",
    "    print(f'  {label:2d} ‚Üí {role}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 80 samples | Test: 20 samples\n"
     ]
    }
   ],
   "source": [
    "X = df['skills']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train: {len(X_train)} samples | Test: {len(X_test)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model trained!\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Cell 5: Build Pipeline (TF-IDF + Logistic Regression) ‚îÄ‚îÄ\n",
    "# TF-IDF converts skill text ‚Üí numeric vector\n",
    "# Logistic Regression gives probability scores per class ‚Üí perfect for top-3\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),    \n",
    "    min_df=1,\n",
    "    max_features=5000,\n",
    "    sublinear_tf=True,     \n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=5.0,\n",
    "    class_weight='balanced',\n",
    "    solver='lbfgs',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec  = tfidf.transform(X_test)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "print('‚úÖ Model trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_vec)\n",
    "acc    = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test Accuracy: {acc * 100:.1f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "     Backend Developer       1.00      1.00      1.00         2\n",
      "        Cloud Engineer       1.00      1.00      1.00         2\n",
      " Cybersecurity Analyst       1.00      1.00      1.00         2\n",
      "          Data Analyst       1.00      1.00      1.00         2\n",
      "        Data Scientist       1.00      1.00      1.00         2\n",
      "Database Administrator       1.00      1.00      1.00         2\n",
      "       DevOps Engineer       1.00      1.00      1.00         2\n",
      "           ML Engineer       1.00      1.00      1.00         2\n",
      "      Mobile Developer       1.00      1.00      1.00         2\n",
      "         Web Developer       1.00      1.00      1.00         2\n",
      "\n",
      "              accuracy                           1.00        20\n",
      "             macro avg       1.00      1.00      1.00        20\n",
      "          weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input skills: \"python machine learning tensorflow docker kubernetes git sql\"\n",
      "\n",
      "Top 3 predicted roles:\n",
      "  #1: Data Scientist ‚Äî 33.9% confidence\n",
      "  #2: ML Engineer ‚Äî 16.2% confidence\n",
      "  #3: DevOps Engineer ‚Äî 11.6% confidence\n"
     ]
    }
   ],
   "source": [
    "sample = 'python machine learning tensorflow docker kubernetes git sql'\n",
    "vec    = tfidf.transform([sample])\n",
    "proba  = clf.predict_proba(vec)[0]\n",
    "\n",
    "top3_idx   = np.argsort(proba)[::-1][:3]\n",
    "top3_roles = [(le.classes_[i], round(proba[i] * 100, 1)) for i in top3_idx]\n",
    "\n",
    "print(f'Input skills: \"{sample}\"\\n')\n",
    "print('Top 3 predicted roles:')\n",
    "for rank, (role, pct) in enumerate(top3_roles, 1):\n",
    "    print(f'  #{rank}: {role} ‚Äî {pct}% confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "   models/tfidf.pkl\n",
      "   models/job_model.pkl\n",
      "   models/label_encoder.pkl\n",
      "\n",
      "Done! Copy the models/ folder into your Flask project root.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'models/tfidf.pkl')\n",
    "joblib.dump(clf,   'models/job_model.pkl')\n",
    "joblib.dump(le,    'models/label_encoder.pkl')\n",
    "\n",
    "print('Saved:')\n",
    "print('   models/tfidf.pkl')\n",
    "print('   models/job_model.pkl')\n",
    "print('   models/label_encoder.pkl')\n",
    "print('\\nDone! Copy the models/ folder into your Flask project root.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
